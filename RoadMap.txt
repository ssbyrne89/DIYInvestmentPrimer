
    Create Repo
        (config GitActions??)

    Create ReadMe file

    # User Stories

    Parse Stories into tasks



Prototyping our MVP locally

    ###Create the database table model -- S.B.

    ###Create a DOTENV file for environment variables to keep api keys guarded -- S.B.

    ###Create a SQLite database for the initial prototyping  -- Pair Programming
    
    ###Migrate AlphaVantage API call function from Notebook to  the `database.py` file 
    with the rest of the app - Pair Programming

    ###Populate the table -- Pair Programming
       ###rewrite `parseDataFromAlphaVAPI()` to use two keys
       ### add something that will log the API calls per key
       

    ### if api call returns the following message: {
    "Note": "Thank you for using Alpha Vantage! 
     Our standard API call frequency is 5 calls per
     minute and 500 calls per day. Please visit 
     https://www.alphavantage.co/premium/ if you would 
     like to target a higher API call frequency."
     }
     this is the message given when too many api calls have been
     made in a minute or a day
     if this message is returned then set the sleep() to pause
     looping for 65 seconds and start at the top of the loop with
     the value of `i` most recently used to make an api call
    
    ###rewrite `parse` and `populate` functions to commit to the DB every ten companies -- E.G.
    
    

    ###Design the the graph/table for `best dividend growth companies on the S&P500`
        #Take photo of example graph drawing and put it into the repo for reference -- S.B.
    


    Refactor:
        # parseData.. function: Clean and simplify api-key selection 
        # encounteredError function: separate the "Note" handle into it's own function
    
    ### Change SandP500 csv - change ticker for BF.B to BF-B

    # Change column names in parse function
    
    move the `populateDB()` to the if __name__ = "main"???
    

    change column datatypes in db(at import)

    Add the chron so that it automatically updates the database monthly

    write the queries -- E.G.
        # wants to easily find out which stocks pay dividends, in order to make a good decision about investing
        query that returns the DIVIDEND YIELD
        query all companies, avg price closing price per year, dividend
        
        

ANALYSIS
    Put into a pandas dataframe Plot the results of the above query --E.G. with some Pair Programming

    Create create visualization:
        DIVIDEND YIELD chart
        "top 20 companies with best dividend yield" CHART NAME


FRONTEND
    Embed the data visualization of the graph as Plotly embedding on the HTML template -- S.B.
        Do the same for every chart we make
        Chart ideas

MVP Frontend:
    Landing Page
    about page
    strategies page (show our charts and analysis from the mvp)

DATABASE:
    Repopulate DB
    Create a DB table for company profiles
    Add more columns and stuff after mvp for the sake of ml analysis


Deployment

    Migrate data to Postgres AWS

    host on AWS via elastic beanstalk

