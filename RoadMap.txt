
    Create Repo
        (config GitActions??)

    Create ReadMe file

    # User Stories

    Parse Stories into tasks



Prototyping our MVP locally

    ###Create the database table model -- S.B.

    ###Create a DOTENV file for environment variables to keep api keys guarded -- S.B.

    ###Create a SQLite database for the initial prototyping  -- Pair Programming
    
    ###Migrate AlphaVantage API call function from Notebook to  the `database.py` file 
    with the rest of the app - Pair Programming

    ###Populate the table -- Pair Programming
       ###rewrite `parseDataFromAlphaVAPI()` to use two keys
       ### add something that will log the API calls per key
       

    ### if api call returns the following message: {
    "Note": "Thank you for using Alpha Vantage! 
     Our standard API call frequency is 5 calls per
     minute and 500 calls per day. Please visit 
     https://www.alphavantage.co/premium/ if you would 
     like to target a higher API call frequency."
     }
     this is the message given when too many api calls have been
     made in a minute or a day
     if this message is returned then set the sleep() to pause
     looping for 65 seconds and start at the top of the loop with
     the value of `i` most recently used to make an api call
    
    ###rewrite `parse` and `populate` functions to commit to the DB every ten companies -- E.G.
    
    

    ###Design the the graph/table for `best dividend growth companies on the S&P500`
        #Take photo of example graph drawing and put it into the repo for reference -- S.B.
    
    Refactor:
        parseData.. function: Clean and simplify api-key selection 
        encounteredError function: separate the "Note" handle into it's own function
    
    Change SandP500 csv - change ticker for BF.B to BF-B

    move the `populateDB()` to the if __name__ = "main"???

    Add the chron so that it automatically updates the database monthly
    write the queries for to produce the `best dividend growth companies on the S&P500` -- E.G.

    Put into a pandas dataframe Plot the results of the above query --E.G. with some Pair Programming

    Embed the data visualization of the graph as Plotly embedding on the HTML template -- S.B.


Deployment

    Migrate data to Postgres AWS

    host on AWS via elastic beanstalk

